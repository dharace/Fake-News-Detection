{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake News Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharace/Fake-News-Detection/blob/main/Fake_News_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "He4udPPc5JTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f5d271-e4fc-48ba-deb9-a7c9f0e4e629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.5)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "@author: Dhara & Avi\n",
        "\"\"\"\n",
        "\n",
        "!pip install -U scikit-learn\n",
        "!pip install numpy\n",
        "!pip install scipy\n",
        "# !pip3 install -U scikit-learn scipy matplotlib\n",
        "\n",
        "# !pip install sklearn\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import sklearn\n",
        "\n",
        "#import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import nltk\n",
        "import nltk.corpus \n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#before reading the files, setup the working directory to point to project repo\n",
        "#reading data files \n",
        "\n",
        "test_filename = '/content/drive/MyDrive/Fake News Detection/test.csv'\n",
        "train_filename = '/content/drive/MyDrive/Fake News Detection/train.csv'\n",
        "valid_filename = '/content/drive/MyDrive/Fake News Detection/valid.csv'\n",
        "\n",
        "train_news = pd.read_csv(train_filename)\n",
        "test_news = pd.read_csv(test_filename)\n",
        "valid_news = pd.read_csv(valid_filename)\n",
        "\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "nt1EBYHOk0I0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cec61e-d863-432a-9a79-bf52c8b5e0ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data observation\n",
        "def data_obs():\n",
        "  print(\"training dataset size:\")\n",
        "  print(train_news.shape)\n",
        "  print(train_news.head(10))\n",
        "\n",
        "#below dataset were used for testing and validation purposes\n",
        "  print(test_news.shape)\n",
        "  print(test_news.head(10))\n",
        "    \n",
        "  print(valid_news.shape)\n",
        "  print(valid_news.head(10))"
      ],
      "metadata": {
        "id": "K1Vn0gi56vNg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the data by calling below function\n",
        "#data_obs()\n",
        "\n",
        "#distribution of classes for prediction\n",
        "def create_distribution(dataFile):\n",
        "    return sb.countplot(x='Label', data=dataFile, palette='hls')\n",
        "    \n",
        "\n",
        "#by calling below we can see that training, test and valid data seems to be failry evenly distributed between the classes\n",
        "create_distribution(train_news)\n",
        "create_distribution(test_news)\n",
        "create_distribution(valid_news)\n"
      ],
      "metadata": {
        "id": "0hhN85htlUsg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "c6b44dca-8d54-4bba-e1fa-f66ade9d2d6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data integrity check (missing label values)\n",
        "#none of the datasets contains missing values therefore no cleaning required\n",
        "def data_qualityCheck():\n",
        "    \n",
        "    print(\"Checking data qualitites...\")\n",
        "    train_news.isnull().sum()\n",
        "    train_news.info()\n",
        "        \n",
        "    print(\"check finished.\")\n",
        "\n",
        "    #below datasets were used to \n",
        "    test_news.isnull().sum()\n",
        "    test_news.info()\n",
        "\n",
        "    valid_news.isnull().sum()\n",
        "    valid_news.info()\n",
        "\n",
        "#run the below function call to see the quality check results\n",
        "#data_qualityCheck()"
      ],
      "metadata": {
        "id": "HAge56QClbjB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_stemmer = SnowballStemmer('english')\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "#Stemming\n",
        "def stem_tokens(tokens, stemmer):\n",
        "    stemmed = []\n",
        "    for token in tokens:\n",
        "        stemmed.append(stemmer.stem(token))\n",
        "    return stemmed"
      ],
      "metadata": {
        "id": "IHp4NKBDlfq9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#process the data\n",
        "def process_data(data,exclude_stopword=True,stem=True):\n",
        "    tokens = [w.lower() for w in data]\n",
        "    tokens_stemmed = tokens\n",
        "    tokens_stemmed = stem_tokens(tokens, eng_stemmer)\n",
        "    tokens_stemmed = [w for w in tokens_stemmed if w not in stopwords ]\n",
        "    return tokens_stemmed\n"
      ],
      "metadata": {
        "id": "xGLvnKAAllO-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating ngrams\n",
        "#unigram \n",
        "def create_unigram(words):\n",
        "    assert type(words) == list\n",
        "    return words\n",
        "\n",
        "#bigram\n",
        "def create_bigrams(words):\n",
        "    assert type(words) == list\n",
        "    skip = 0\n",
        "    join_str = \" \"\n",
        "    Len = len(words)\n",
        "    if Len > 1:\n",
        "        lst = []\n",
        "        for i in range(Len-1):\n",
        "            for k in range(1,skip+2):\n",
        "                if i+k < Len:\n",
        "                    lst.append(join_str.join([words[i],words[i+k]]))\n",
        "    else:\n",
        "        #set it as unigram\n",
        "        lst = create_unigram(words)\n",
        "    return lst\n",
        "\n",
        "#trigrams\n",
        "def create_trigrams(words):\n",
        "    assert type(words) == list\n",
        "    skip = 0\n",
        "    join_str = \" \"\n",
        "    Len = len(words)\n",
        "    if Len > 2:\n",
        "        lst = []\n",
        "        for i in range(1,skip+2):\n",
        "            for k1 in range(1, skip+2):\n",
        "                for k2 in range(1,skip+2):\n",
        "                  if i+k1 < Len and i+k1+k2 < Len:\n",
        "                            lst.append(join_str.join([words[i], words[i+k1],words[i+k1+k2]]))\n",
        "        else:\n",
        "            #set is as bigram\n",
        "            lst = create_bigrams(words)\n",
        "    return lst"
      ],
      "metadata": {
        "id": "yZB7YZy6l2kc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ],
      "metadata": {
        "id": "N-cuDDStnQcF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doc = ['runners like running and thus they run','this is a test for tokens']\n",
        "#tokenizer([word for line in test_news.iloc[:,1] for word in line.lower().split()])\n",
        "\n",
        "#show the distribution of labels in the train and test data\n",
        "\"\"\"def create_datafile(filename)\n",
        "    #function to slice the dataframe to keep variables necessary to be used for classification\n",
        "    return \"return df to be used\"\n",
        "\"\"\"\n",
        "    \n",
        "\"\"\"#converting multiclass labels present in our datasets to binary class labels\n",
        "for i , row in data_TrainNews.iterrows():\n",
        "    if (data_TrainNews.iloc[:,0] == \"mostly-true\" | data_TrainNews.iloc[:,0] == \"half-true\" | data_TrainNews.iloc[:,0] == \"true\"):\n",
        "        data_TrainNews.iloc[:,0] = \"true\"\n",
        "    else :\n",
        "        data_TrainNews.iloc[:,0] = \"false\"\n",
        "        \n",
        "for i,row in data_TrainNews.iterrows():\n",
        "    print(row)\n",
        "\"\"\"\n",
        "    \n"
      ],
      "metadata": {
        "id": "j6YSxV1knYa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9c443d0b-d306-4bcc-97ce-d2ad239a120a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#converting multiclass labels present in our datasets to binary class labels\\nfor i , row in data_TrainNews.iterrows():\\n    if (data_TrainNews.iloc[:,0] == \"mostly-true\" | data_TrainNews.iloc[:,0] == \"half-true\" | data_TrainNews.iloc[:,0] == \"true\"):\\n        data_TrainNews.iloc[:,0] = \"true\"\\n    else :\\n        data_TrainNews.iloc[:,0] = \"false\"\\n        \\nfor i,row in data_TrainNews.iterrows():\\n    print(row)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we will start with simple bag of words technique \n",
        "#creating feature vector - document term matrix\n",
        "countV = CountVectorizer()\n",
        "train_count = countV.fit_transform(train_news['Statement'].values)\n",
        "\n",
        "print(countV)\n",
        "print(train_count)"
      ],
      "metadata": {
        "id": "GFeniEK64WSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4e2aa7-7c70-4479-9e30-de1a46a0d90f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer()\n",
            "  (0, 9676)\t1\n",
            "  (0, 10988)\t1\n",
            "  (0, 1044)\t1\n",
            "  (0, 6639)\t1\n",
            "  (0, 8376)\t1\n",
            "  (0, 5115)\t1\n",
            "  (0, 10709)\t1\n",
            "  (0, 11036)\t1\n",
            "  (0, 11296)\t1\n",
            "  (0, 615)\t1\n",
            "  (0, 7728)\t1\n",
            "  (0, 3278)\t1\n",
            "  (1, 10988)\t1\n",
            "  (1, 11934)\t2\n",
            "  (1, 3434)\t1\n",
            "  (1, 3185)\t1\n",
            "  (1, 7672)\t1\n",
            "  (1, 2475)\t1\n",
            "  (1, 10425)\t1\n",
            "  (1, 6052)\t1\n",
            "  (1, 10426)\t2\n",
            "  (1, 7418)\t1\n",
            "  (1, 4860)\t1\n",
            "  (1, 11138)\t1\n",
            "  (1, 7674)\t1\n",
            "  :\t:\n",
            "  (10239, 10988)\t1\n",
            "  (10239, 7672)\t2\n",
            "  (10239, 11110)\t2\n",
            "  (10239, 5267)\t1\n",
            "  (10239, 7828)\t1\n",
            "  (10239, 7824)\t1\n",
            "  (10239, 1159)\t1\n",
            "  (10239, 12151)\t2\n",
            "  (10239, 6327)\t1\n",
            "  (10239, 6603)\t1\n",
            "  (10239, 11013)\t1\n",
            "  (10239, 11004)\t1\n",
            "  (10239, 3309)\t1\n",
            "  (10239, 12158)\t1\n",
            "  (10239, 11660)\t2\n",
            "  (10239, 799)\t1\n",
            "  (10239, 2568)\t1\n",
            "  (10239, 11622)\t1\n",
            "  (10239, 2549)\t1\n",
            "  (10239, 10660)\t1\n",
            "  (10239, 8996)\t1\n",
            "  (10239, 10918)\t1\n",
            "  (10239, 3989)\t1\n",
            "  (10239, 10594)\t1\n",
            "  (10239, 6853)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print training doc term matrix\n",
        "#we have matrix of size of (10240, 12196) by calling below\n",
        "def get_countVectorizer_stats():\n",
        "    \n",
        "    #vocab size\n",
        "    train_count.shape\n",
        "\n",
        "    #check vocabulary using below command\n",
        "    print(countV.vocabulary_)\n",
        "\n",
        "    #get feature names\n",
        "    print(countV.get_feature_names()[:25])\n"
      ],
      "metadata": {
        "id": "f7ntD19l4-qW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create tf-df frequency features\n",
        "#tf-idf \n",
        "tfidfV = TfidfTransformer()\n",
        "train_tfidf = tfidfV.fit_transform(train_count)\n",
        "\n",
        "def get_tfidf_stats():\n",
        "    train_tfidf.shape\n",
        "    #get train data feature names \n",
        "    print(train_tfidf.A[:10])"
      ],
      "metadata": {
        "id": "Qng-O6Yb5HQB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bag of words - with n-grams\n",
        "#countV_ngram = CountVectorizer(ngram_range=(1,3),stop_words='english')\n",
        "#tfidf_ngram  = TfidfTransformer(use_idf=True,smooth_idf=True)\n",
        "\n",
        "tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)\n",
        "\n",
        "#POS Tagging\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        "\n",
        "cutoff = int(.75 * len(tagged_sentences))\n",
        "training_sentences = train_news['Statement']\n",
        " \n",
        "print(training_sentences)\n"
      ],
      "metadata": {
        "id": "QjqG7eIJ5LKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3e164a-3083-4501-878f-873797f47ffe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Says the Annies List political group supports ...\n",
            "1        When did the decline of coal start? It started...\n",
            "2        Hillary Clinton agrees with John McCain \"by vo...\n",
            "3        Health care reform legislation is likely to ma...\n",
            "4        The economic turnaround started at the end of ...\n",
            "                               ...                        \n",
            "10235    There are a larger number of shark attacks in ...\n",
            "10236    Democrats have now become the party of the [At...\n",
            "10237    Says an alternative to Social Security that op...\n",
            "10238    On lifting the U.S. Cuban embargo and allowing...\n",
            "10239    The Department of Veterans Affairs has a manua...\n",
            "Name: Statement, Length: 10240, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training POS tagger based on words\n",
        "def features(sentence, index):\n",
        "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
        "    return {\n",
        "        'word': sentence[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
        "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
        "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
        "        'prefix-1': sentence[index][0],\n",
        "        'prefix-2': sentence[index][:2],\n",
        "        'prefix-3': sentence[index][:3],\n",
        "        'suffix-1': sentence[index][-1],\n",
        "        'suffix-2': sentence[index][-2:],\n",
        "        'suffix-3': sentence[index][-3:],\n",
        "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "        'has_hyphen': '-' in sentence[index],\n",
        "        'is_numeric': sentence[index].isdigit(),\n",
        "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
        "    }"
      ],
      "metadata": {
        "id": "JVGiJ7Z05vsI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function to strip tags from tagged corpus\t\n",
        "def untag(tagged_sentence):\n",
        "    return [w for w, t in tagged_sentence]"
      ],
      "metadata": {
        "id": "8vm6jRSF50B-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Word2Vec\n",
        "\n",
        "glove_6B_50d = '/content/drive/MyDrive/Fake News Detection/glove.6B.50d.txt'\n",
        "\n",
        "with open(glove_6B_50d, \"rb\") as lines:\n",
        "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
        "           for line in lines}\n",
        "\n",
        "#model = gensim.models.Word2Vec(X, size=100) # x be tokenized text\n",
        "#w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n"
      ],
      "metadata": {
        "id": "JlD7J4pg52r_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(word2vec.itervalues().next())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])\n",
        "\n",
        "\"\"\"\n",
        "class TfidfEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        self.word2weight = None\n",
        "        self.dim = len(word2vec.itervalues().next())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
        "        tfidf.fit(X)\n",
        "        # if a word was never seen - it must be at least as infrequent\n",
        "        # as any of the known words - so the default idf is the max of \n",
        "        # known idf's\n",
        "        max_idf = max(tfidf.idf_)\n",
        "        self.word2weight = defaultdict(\n",
        "            lambda: max_idf,\n",
        "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
        "                         for w in words if w in self.word2vec] or\n",
        "                        [np.zeros(self.dim)], axis=0)\n",
        "                for words in X\n",
        "            ])\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EKKifAXE7K7l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "edcdd7e0-ad79-464a-bacf-954353fc2f7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass TfidfEmbeddingVectorizer(object):\\n    def __init__(self, word2vec):\\n        self.word2vec = word2vec\\n        self.word2weight = None\\n        self.dim = len(word2vec.itervalues().next())\\n\\n    def fit(self, X, y):\\n        tfidf = TfidfVectorizer(analyzer=lambda x: x)\\n        tfidf.fit(X)\\n        # if a word was never seen - it must be at least as infrequent\\n        # as any of the known words - so the default idf is the max of \\n        # known idf's\\n        max_idf = max(tfidf.idf_)\\n        self.word2weight = defaultdict(\\n            lambda: max_idf,\\n            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\\n\\n        return self\\n\\n    def transform(self, X):\\n        return np.array([\\n                np.mean([self.word2vec[w] * self.word2weight[w]\\n                         for w in words if w in self.word2vec] or\\n                        [np.zeros(self.dim)], axis=0)\\n                for words in X\\n            ])\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#string to test\n",
        "doc_new = ['obama is running for president in 2016']\n",
        "\n",
        "#the feature selection has been done in FeatureSelection.py module. here we will create models using those features for prediction\n",
        "\n",
        "#first we will use bag of words techniques\n",
        "\n",
        "#building classifier using naive bayes \n",
        "nb_pipeline = Pipeline([\n",
        "        ('NBCV', countV),\n",
        "        ('nb_clf',MultinomialNB())])\n",
        "\n",
        "nb_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_nb = nb_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_nb == test_news['Label'])\n"
      ],
      "metadata": {
        "id": "_ZePgdO3G6fK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85b4522-83e2-430f-fa8a-3267ae6679af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6072128577028616"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building classifier using logistic regression\n",
        "logR_pipeline = Pipeline([\n",
        "        ('LogRCV',countV),\n",
        "        ('LogR_clf',LogisticRegression())\n",
        "        ])\n",
        "\n",
        "logR_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR = logR_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR == test_news['Label'])"
      ],
      "metadata": {
        "id": "GGrwbgamHPS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec738da-b382-4115-ef80-5bf0e2298cde"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6013328106624853"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building Linear SVM classfier\n",
        "svm_pipeline = Pipeline([\n",
        "        ('svmCV',countV),\n",
        "        ('svm_clf',svm.LinearSVC())\n",
        "        ])\n",
        "\n",
        "svm_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_svm = svm_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_svm == test_news['Label'])\n"
      ],
      "metadata": {
        "id": "u5v2nboDHgGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c6a993-2788-4e1b-cd8b-c23ffd1a3bdb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5727165817326538"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using SVM Stochastic Gradient Descent on hinge loss\n",
        "sgd_pipeline = Pipeline([\n",
        "        ('svm2CV',countV),\n",
        "        ('svm2_clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter =5))\n",
        "        ])\n",
        "\n",
        "sgd_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_sgd = sgd_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_sgd == test_news['Label'])"
      ],
      "metadata": {
        "id": "gFa1fE1_HpsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe92b5ec-2efe-427c-815f-c1c6622cfe8c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6154449235593885"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "random_forest = Pipeline([\n",
        "        ('rfCV', countV),\n",
        "        ('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))\n",
        "        ])\n",
        "    \n",
        "random_forest.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf = random_forest.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf == test_news['Label'])"
      ],
      "metadata": {
        "id": "8LDqdBxKIckC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c94ab2-2956-4736-b509-3edaa407fe2e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6295570364562917"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#User defined functon for K-Fold cross validatoin\n",
        "def build_confusion_matrix(classifier):\n",
        "    \n",
        "    k_fold = KFold(n_splits=5)\n",
        "    scores = []\n",
        "    confusion = np.array([[0,0],[0,0]])\n",
        "\n",
        "    for train_ind, test_ind in k_fold.split(train_news):\n",
        "        train_text = train_news.iloc[train_ind]['Statement'] \n",
        "        train_y = train_news.iloc[train_ind]['Label']\n",
        "    \n",
        "        test_text = train_news.iloc[test_ind]['Statement']\n",
        "        test_y = train_news.iloc[test_ind]['Label']\n",
        "        \n",
        "        classifier.fit(train_text,train_y)\n",
        "        predictions = classifier.predict(test_text)\n",
        "        \n",
        "        confusion += confusion_matrix(test_y,predictions)\n",
        "        score = f1_score(test_y,predictions)\n",
        "        scores.append(score)\n",
        "    \n",
        "    return (print('Total statements classified:', len(train_news)),\n",
        "    print('Score:', sum(scores)/len(scores)),\n",
        "    print('score length', len(scores)),\n",
        "    print('Confusion matrix:'),\n",
        "    print(confusion))"
      ],
      "metadata": {
        "id": "v1UoparZIC1v"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-fold cross validation for all classifiers\n",
        "build_confusion_matrix(nb_pipeline)\n",
        "build_confusion_matrix(logR_pipeline)\n",
        "build_confusion_matrix(svm_pipeline)\n",
        "build_confusion_matrix(sgd_pipeline)\n",
        "build_confusion_matrix(random_forest)"
      ],
      "metadata": {
        "id": "CI5OxFBiIS3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c67e0f-e8c7-4d93-869a-e9d06957269e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.66961153965076\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2118 2370]\n",
            " [1664 4088]]\n",
            "Total statements classified: 10240\n",
            "Score: 0.6466692934443682\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2254 2234]\n",
            " [1936 3816]]\n",
            "Total statements classified: 10240\n",
            "Score: 0.6104687487924283\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2260 2228]\n",
            " [2246 3506]]\n",
            "Total statements classified: 10240\n",
            "Score: 0.6437375566570506\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2284 2204]\n",
            " [1968 3784]]\n",
            "Total statements classified: 10240\n",
            "Score: 0.7053196538324163\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[1832 2656]\n",
            " [1171 4581]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So far we have used bag of words technique to extract the features and passed those featuers into classifiers. We have also seen the\n",
        "# f1 scores of these classifiers. now lets enhance these features using term frequency weights with various n-grams\n",
        "\n",
        "##Now using n-grams\n",
        "\n",
        "#naive-bayes classifier\n",
        "nb_pipeline_ngram = Pipeline([\n",
        "        ('nb_tfidf',tfidf_ngram),\n",
        "        ('nb_clf',MultinomialNB())])\n",
        "\n",
        "nb_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_nb_ngram = nb_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_nb_ngram == test_news['Label'])"
      ],
      "metadata": {
        "id": "s4OOYb21KGkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba16d87b-34cf-4344-9c24-d76102680a3a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5938847510780086"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression classifier\n",
        "logR_pipeline_ngram = Pipeline([\n",
        "        ('LogR_tfidf', tfidf_ngram),\n",
        "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
        "        ])\n",
        "\n",
        "logR_pipeline_ngram.fit(train_news['Statement'], train_news['Label'])\n",
        "predicted_LogR_ngram = logR_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR_ngram == test_news['Label'])"
      ],
      "metadata": {
        "id": "v8xNMIuzKeWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89db9a73-a11c-49c6-cdd7-c8a30ce24534"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6193649549196394"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#linear SVM classifier\n",
        "svm_pipeline_ngram = Pipeline([\n",
        "        ('svm_tfidf',tfidf_ngram),\n",
        "        ('svm_clf',svm.LinearSVC())\n",
        "        ])\n",
        "\n",
        "svm_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_svm_ngram = svm_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_svm_ngram == test_news['Label'])"
      ],
      "metadata": {
        "id": "GobjvrUXKn4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8007a25f-bfaf-4182-e973-262a7681794a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6170129361034888"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sgd classifier\n",
        "sgd_pipeline_ngram = Pipeline([\n",
        "         ('sgd_tfidf', tfidf_ngram),\n",
        "         ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5))\n",
        "         ])\n",
        "\n",
        "sgd_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_sgd_ngram = sgd_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_sgd_ngram == test_news['Label'])"
      ],
      "metadata": {
        "id": "gFlYa9ofKvtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b58f26-3e68-4f8b-8fa5-fe0de45bffd0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5417483339866719"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest classifier\n",
        "random_forest_ngram = Pipeline([\n",
        "        ('rf_tfidf', tfidf_ngram),\n",
        "        ('rf_clf', RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
        "        ])\n",
        "    \n",
        "random_forest_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf_ngram = random_forest_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf_ngram == test_news['Label'])"
      ],
      "metadata": {
        "id": "r_pBHZ3qK6WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1da7a0f-ae45-49d3-9d9f-3a2bd395244d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6032928263426107"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#K-fold cross validation for all classifiers\n",
        "build_confusion_matrix(nb_pipeline_ngram)\n",
        "build_confusion_matrix(logR_pipeline_ngram)\n",
        "build_confusion_matrix(svm_pipeline_ngram)\n",
        "build_confusion_matrix(sgd_pipeline_ngram)\n",
        "build_confusion_matrix(random_forest_ngram)"
      ],
      "metadata": {
        "id": "yWthoIPrLCSB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "8a4365f5-0ea0-43bd-d2a4-cf98765d75bb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-208362829298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#K-fold cross validation for all classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_pipeline_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogR_pipeline_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_pipeline_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbuild_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_pipeline_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-21f369dfa726>\u001b[0m in \u001b[0;36mbuild_confusion_matrix\u001b[0;34m(classifier)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_news\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             )\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1349\u001b[0m             )\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[0;34m(self, X, vocabulary)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreordered\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodifies\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \"\"\"\n\u001b[0;32m-> 1134\u001b[0;31m         \u001b[0msorted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m         \u001b[0mmap_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_news['Label'], predicted_nb_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_LogR_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_svm_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_sgd_ngram))\n",
        "print(classification_report(test_news['Label'], predicted_rf_ngram))\n",
        "\n",
        "test_news['Label'].shape"
      ],
      "metadata": {
        "id": "Hn-qb8rdLGl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00dba6db-b6d5-4cab-f0a2-a16708e2d543"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.72      0.19      0.30      1169\n",
            "        True       0.58      0.94      0.71      1382\n",
            "\n",
            "    accuracy                           0.59      2551\n",
            "   macro avg       0.65      0.56      0.51      2551\n",
            "weighted avg       0.64      0.59      0.52      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.64      0.39      0.49      1169\n",
            "        True       0.61      0.81      0.70      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.62      0.60      0.59      2551\n",
            "weighted avg       0.62      0.62      0.60      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.61      0.47      0.53      1169\n",
            "        True       0.62      0.74      0.68      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.61      0.61      0.60      2551\n",
            "weighted avg       0.62      0.62      0.61      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.00      0.00      0.00      1169\n",
            "        True       0.54      1.00      0.70      1382\n",
            "\n",
            "    accuracy                           0.54      2551\n",
            "   macro avg       0.27      0.50      0.35      2551\n",
            "weighted avg       0.29      0.54      0.38      2551\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.58      0.48      0.52      1169\n",
            "        True       0.62      0.71      0.66      1382\n",
            "\n",
            "    accuracy                           0.60      2551\n",
            "   macro avg       0.60      0.59      0.59      2551\n",
            "weighted avg       0.60      0.60      0.60      2551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2551,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Out of all the models fitted, we would take 2 best performing model. we would call them candidate models\n",
        "# from the confusion matrix, we can see that random forest and logistic regression are best performing \n",
        "# in terms of precision and recall (take a look into false positive and true negative counts which appeares\n",
        "# to be low compared to rest of the models)\n",
        "\n",
        "#grid-search parameter optimization\n",
        "#random forest classifier parameters\n",
        "parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'rf_tfidf__use_idf': (True, False),\n",
        "               'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_"
      ],
      "metadata": {
        "id": "7IfVmBjALbbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "ebbd9f60-0a1e-4b5f-8083-c6c7e33d6003"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9dae749abab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_forest_ngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_news\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Statement'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_news\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression parameters\n",
        "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'LogR_tfidf__use_idf': (True, False),\n",
        "               'LogR_tfidf__smooth_idf': (True, False)\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_"
      ],
      "metadata": {
        "id": "dY3oL4N8LgJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear SVM \n",
        "parameters = {'svm_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'svm_tfidf__use_idf': (True, False),\n",
        "               'svm_tfidf__smooth_idf': (True, False),\n",
        "               'svm_clf__penalty': ('l1','l2'),\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_"
      ],
      "metadata": {
        "id": "U9E8L3ZMLg7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#by running above commands we can find the model with best performing parameters\n",
        "\n",
        "#running both random forest and logistic regression models again with best parameter found with GridSearch method\n",
        "random_forest_final = Pipeline([\n",
        "        ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
        "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
        "        ])\n",
        "    \n",
        "random_forest_final.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf_final = random_forest_final.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf_final == test_news['Label'])\n",
        "print(classification_report(test_news['Label'], predicted_rf_final))\n"
      ],
      "metadata": {
        "id": "TCgd5rtnlqQr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65c84ad-618c-433c-b33b-db43cf5ace18"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.75      0.00      0.01      1169\n",
            "        True       0.54      1.00      0.70      1382\n",
            "\n",
            "    accuracy                           0.54      2551\n",
            "   macro avg       0.65      0.50      0.35      2551\n",
            "weighted avg       0.64      0.54      0.38      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logR_pipeline_final = Pipeline([\n",
        "        #('LogRCV',countV_ngram),\n",
        "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
        "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
        "        ])\n",
        "\n",
        "logR_pipeline_final.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR_final = logR_pipeline_final.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR_final == test_news['Label'])\n",
        "#accuracy = 0.62\n",
        "print(classification_report(test_news['Label'], predicted_LogR_final))"
      ],
      "metadata": {
        "id": "zr86TM0Bm8CY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa0a0f7-453b-47a1-8994-a74022558b57"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.64      0.38      0.48      1169\n",
            "        True       0.61      0.82      0.70      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.62      0.60      0.59      2551\n",
            "weighted avg       0.62      0.62      0.60      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by running both random forest and logistic regression with GridSearch's best parameter estimation, we found that for random \n",
        "# forest model with n-gram has better accuracty than with the parameter estimated. The logistic regression model with best parameter \n",
        "# has almost similar performance as n-gram model so logistic regression will be out choice of model for prediction.\n",
        "\n",
        "#saving best model to the disk\n",
        "model_file = '/content/drive/MyDrive/Fake News Detection/final_model.sav'\n",
        "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))"
      ],
      "metadata": {
        "id": "fBho7fHDSnHT"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting learing curve\n",
        "def plot_learing_curve(pipeline,title):\n",
        "    size = 10000\n",
        "    cv = KFold(size, shuffle=True)\n",
        "    \n",
        "    X = train_news[\"Statement\"]\n",
        "    y = train_news[\"Label\"]\n",
        "    \n",
        "    pl = pipeline\n",
        "    pl.fit(X,y)\n",
        "    \n",
        "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
        "       \n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "     \n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    \n",
        "    # box-like grid\n",
        "    plt.grid()\n",
        "    \n",
        "    # plot the std deviation as a transparent range at each training set size\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    \n",
        "    # plot the average training and test score lines at each training set size\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    \n",
        "    # sizes the window for readability and displays the plot\n",
        "    # shows error from 0 to 1.1\n",
        "    plt.ylim(-.1,1.1)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3DDnohakS4fX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#below command will plot learing curves for each of the classifiers\n",
        "plot_learing_curve(logR_pipeline_ngram,\"Naive-bayes Classifier\")\n",
        "plot_learing_curve(nb_pipeline_ngram,\"LogisticRegression Classifier\")\n",
        "plot_learing_curve(svm_pipeline_ngram,\"SVM Classifier\")\n",
        "plot_learing_curve(sgd_pipeline_ngram,\"SGD Classifier\")\n",
        "plot_learing_curve(random_forest_ngram,\"RandomForest Classifier\")"
      ],
      "metadata": {
        "id": "Ra-sETEXS89L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by plotting the learning cureve for logistic regression, it can be seen that cross-validation score is stagnating throughout and it \n",
        "# is unable to learn from data. Also we see that there are high errors that indicates model is simple and we may want to increase the\n",
        "# model complexity.\n",
        "\n",
        "\n",
        "#plotting Precision-Recall curve\n",
        "def plot_PR_curve(classifier):\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(test_news['Label'], classifier)\n",
        "    average_precision = average_precision_score(test_news['Label'], classifier)\n",
        "    \n",
        "    plt.step(recall, precision, color='b', alpha=0.2,\n",
        "             where='post')\n",
        "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
        "                     color='b')\n",
        "    \n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title('2-class Random Forest Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "              average_precision))\n",
        "    \n",
        "plot_PR_curve(predicted_LogR_ngram)\n",
        "plot_PR_curve(predicted_rf_ngram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-kVfd9L0TDYy",
        "outputId": "99191b4e-1663-4de7-b4c5-b98eaa5c6f50"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's extract the most informative feature from ifidf vectorizer for all fo the classifiers and see of there are any common\n",
        "# words that we can identify i.e. are these most informative feature acorss the classifiers are same? we will create a function that \n",
        "# will extract top 50 features.\n",
        "\n",
        "\n",
        "def show_most_informative_features(model, vect, clf, text=None, n=50):\n",
        "    # Extract the vectorizer and the classifier from the pipeline\n",
        "    vectorizer = model.named_steps[vect]\n",
        "    classifier = model.named_steps[clf]\n",
        "\n",
        "     # Check to make sure that we can perform this computation\n",
        "    if not hasattr(classifier, 'coef_'):\n",
        "        raise TypeError(\n",
        "            \"Cannot compute most informative features on {}.\".format(\n",
        "                classifier.__class__.__name__\n",
        "            )\n",
        "        )\n",
        "            \n",
        "    if text is not None:\n",
        "        # Compute the coefficients for the text\n",
        "        tvec = model.transform([text]).toarray()\n",
        "    else:\n",
        "        # Otherwise simply use the coefficients\n",
        "        tvec = classifier.coef_\n",
        "\n",
        "    # Zip the feature names with the coefs and sort\n",
        "    coefs = sorted(\n",
        "        zip(tvec[0], vectorizer.get_feature_names()),\n",
        "        reverse=True\n",
        "    )\n",
        "    \n",
        "    # Get the top n and bottom n coef, name pairs\n",
        "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
        "\n",
        "    # Create the output string to return\n",
        "    output = []\n",
        "\n",
        "    # If text, add the predicted value to the output.\n",
        "    if text is not None:\n",
        "        output.append(\"\\\"{}\\\"\".format(text))\n",
        "        output.append(\n",
        "            \"Classified as: {}\".format(model.predict([text]))\n",
        "        )\n",
        "        output.append(\"\")\n",
        "\n",
        "    # Create two columns with most negative and most positive features.\n",
        "    for (cp, fnp), (cn, fnn) in topn:\n",
        "        output.append(\n",
        "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
        "                cp, fnp, cn, fnn\n",
        "            )\n",
        "        )\n",
        "    #return \"\\n\".join(output)\n",
        "    print(output)\n",
        "\n",
        "show_most_informative_features(logR_pipeline_ngram,vect='LogR_tfidf',clf='LogR_clf')\n",
        "show_most_informative_features(nb_pipeline_ngram,vect='nb_tfidf',clf='nb_clf')\n",
        "show_most_informative_features(svm_pipeline_ngram,vect='svm_tfidf',clf='svm_clf')\n",
        "show_most_informative_features(sgd_pipeline_ngram,vect='sgd_tfidf',clf='sgd_clf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGMpLw_HTS8k",
        "outputId": "2d165195-f622-4aeb-80e3-7850ff6d3637"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3.3274        percent    -2.0938      obamacare', '1.8485        million    -1.8249          obama', '1.7409        average    -1.6505           says', '1.6573            day    -1.5980      wisconsin', '1.6514        georgia    -1.4068            rep', '1.6174           debt    -1.3510     government', '1.6029      countries    -1.2283           care', '1.5744          times    -1.2013           plan', '1.4221        highest    -1.1898      president', '1.3850        country    -1.1784   scott walker', '1.3490           half    -1.1635         walker', '1.3286            000    -1.0761         obamas', '1.2220       american    -1.0428          scott', '1.2136            cut    -1.0123           away', '1.2060         months    -0.9792        clinton', '1.1675         states    -0.9715         barack', '1.1637      americans    -0.9658       medicare', '1.0659           rate    -0.9373       stimulus', '1.0616           year    -0.9210          white', '1.0163             60    -0.9001          going', '0.9677           weve    -0.8912        illegal', '0.9563         nearly    -0.8545       care law', '0.9467             10    -0.8433       security', '0.9448       spending    -0.8200         social', '0.9354        college    -0.8193          voted', '0.9205         lowest    -0.8116       increase', '0.9154           ohio    -0.8114           know', '0.8974          terms    -0.8109health care law', '0.8927         cities    -0.8079          group', '0.8724          lower    -0.8040         muslim', '0.8526        poverty    -0.7985   barack obama', '0.8448       trillion    -0.7982      democrats', '0.8389         dollar    -0.7874says barack obama', '0.8356        decades    -0.7829    health care', '0.8198         romney    -0.7332           stop', '0.8091             40    -0.7319       benghazi', '0.8072        workers    -0.7257        hillary', '0.8020        members    -0.7198       supports', '0.7909          worth    -0.7189      gov scott', '0.7899      education    -0.7163    raise taxes', '0.7897          today    -0.7157       deciding', '0.7656             50    -0.7097          china', '0.7655          worst    -0.7043            tom', '0.7632         mccain    -0.6921 says president', '0.7540        torture    -0.6901      dont know', '0.7512says donald trump    -0.6852   middle class', '0.7458        elected    -0.6819       says rep', '0.7385        florida    -0.6812    500 billion', '0.7318        funding    -0.6802       illegals', '0.7250           does    -0.6740          wants']\n",
            "['-8.3713payday lending industry    -12.2861        00 2014', '-8.4628magic number people needed    -12.286100 2014 provisions', '-8.9042promised day office rescind    -12.286100 2014 provisions incorporated', '-9.0073            000    -12.2861        000 000', '-9.0531         proven    -12.2861  000 000 isner', '-9.0703seniors pay prescription drugs    -12.2861000 000 isner mahut', '-9.0724record funding protecting environment    -12.2861   000 000 send', '-9.1189     seven days    -12.2861000 000 send community', '-9.1527insurance currently insurance    -12.2861000 000 weapons', '-9.2066killed commercial    -12.2861000 000 weapons firearms', '-9.2574lost war drug cartels    -12.2861         000 10', '-9.3049   gov carcieri    -12.2861        000 200', '-9.3073falls department    -12.2861    000 200 000', '-9.3333repeat verified report department    -12.2861000 200 000 year', '-9.3532   million cars    -12.2861         000 25', '-9.3927churns climate changing    -12.2861     000 25 000', '-9.4083reform new york times    -12.2861000 25 000 federal', '-9.4189austin largest city nonstop    -12.2861         000 30', '-9.4403jones said victims    -12.2861     000 30 000', '-9.5046said going cut veterans    -12.2861000 30 000 isis', '-9.5119said government takes away    -12.2861        000 300', '-9.5296          didnt    -12.2861    000 300 000', '-9.5309nevada unemployment violent    -12.2861000 300 000 hate', '-9.5527bob mcdonnell launched    -12.2861         000 35', '-9.6188 afford bedroom    -12.2861     000 35 000', '-9.6419partners playboy social networking    -12.2861000 35 000 people', '-9.6504based popular revolution shah    -12.2861000 40 000 year', '-9.6615     says craig    -12.2861        000 400', '-9.6651collapsed construction jobs lost    -12.2861    000 400 000', '-9.6698comply non discrimination laws    -12.2861         000 60', '-9.6766    dog wouldnt    -12.2861     000 60 000', '-9.6805      000 today    -12.2861000 60 000 filled', '-9.6885resources early    -12.2861     000 80 000', '-9.6887local taxpayers government    -12.2861000 80 000 year', '-9.7080false 37 percent total    -12.2861    000 al gore', '-9.7598americans average    -12.2861000 al gore recount', '-9.7625advance keystone xl pipeline    -12.2861   000 american', '-9.7637          obese    -12.2861000 american casualties', '-9.7697endorsement barrow journal    -12.2861000 american casualties iraq', '-9.7704island dem illegal rhode    -12.2861000 americans afghanistan', '-9.7911applied percent    -12.2861000 americans afghanistan iraq', '-9.7921happily photographed holding shirt    -12.2861000 americans area', '-9.8125priority winning primary sponsor    -12.2861000 americans die', '-9.8314governors erased electronic    -12.2861000 americans die year', '-9.8344federal stimulus funds hes    -12.2861000 americans died gunfire', '-9.8371entering diverse class representatives    -12.2861000 americans killed gunfire', '-9.8394percent virginias    -12.2861000 americans lose', '-9.8831mutilation central    -12.2861000 americans lose health', '-9.8886lawyers represent    -12.2861    000 average', '-9.8941     apply 2005    -12.2861000 average private']\n",
            "['1.8707  make drainage    -1.4757largest investment higher', '1.6936      cities 39    -1.2105obamas approval rating', '1.6539americans millions jobs    -1.1936mclane kuster used 293', '1.6317companies increasing taxes    -1.1096       excluded', '1.6210rhode island 28    -1.1001      know 2013', '1.5165   efforts rein    -1.0898pentagon obama administration', '1.2959advocacy immigration increases    -1.0880  anderson road', '1.2499extremists hijacked broad based    -1.0773sector whack governments growing', '1.2222conducted nationwide    -1.0312energy considering rate increase', '1.1749jeb bush held million    -0.9794goes far obamacare medicare', '1.1689intensive care unit cause    -0.9710says university', '1.1270citizens black males    -0.9663fundputs mandate local', '1.0838       00 spent    -0.9563  foreign money', '1.0822900 florida jobs    -0.951333 votes repeal', '1.0279felt americans hating    -0.9330         burger', '1.0227businesses created million    -0.9257  says 48 years', '0.9875represent 75 percent    -0.9149nonprofit groups 2012 election', '0.9781congress implementation obamacare cost    -0.8944       pinellas', '0.9575sequestration spending cuts eliminated    -0.8813rep john barrows', '0.9428     mark udall    -0.8521england patriots', '0.9072houston national    -0.8493employee company makes', '0.9017percent retirees collect    -0.8411  diversity fox', '0.8889congress cut social security    -0.8411campaign idea going', '0.8838buffalos solarcity project andrew    -0.8386says republican gubernatorial candidate', '0.8556children raising school    -0.8283launched twice strikes countries', '0.8526legislation open billions taxpayer    -0.8186 forced use 195', '0.8486colorado congressional candidate    -0.8132appointees experience', '0.8431 democrats went    -0.8120business partner robert gay', '0.8422says american families    -0.8050right bear arms', '0.8400john mccain seven points    -0.8010congress redistricting process', '0.8395parents consent    -0.7970 india expected', '0.8340  served havens    -0.7966decade america budget', '0.8314household incomes went state    -0.7944books automatically little', '0.8312considered extreme    -0.7871   oil reserves', '0.8286office gasoline    -0.7820bush tripling barack', '0.8239sen rob portman calls    -0.7785job training programs wisconsins', '0.8232responsible leading america deal    -0.7783minute midnight', '0.8218     49 percent    -0.7757          seals', '0.8168military installations world    -0.7723    received 60', '0.8144          ideas    -0.7698obama wants unilaterally', '0.8035paying taxes nearly 14    -0.7657pledged budget line', '0.7999prescription drug cost health    -0.7653pelosi inaccurate', '0.7987programs income 43    -0.7639government revenues time', '0.7968court justices deciding    -0.7615says nancy pelosi said', '0.794465 percent thirds new    -0.7557past months president', '0.7915      exercised    -0.7473    reid senate', '0.7903rights thats record    -0.7472plan allow foreign corporation', '0.7889idea turn social    -0.7442   far national', '0.7875islam basically teaches    -0.7432obama administration used', '0.7853city portland manager    -0.7388billion congress approved']\n",
            "['0.4577  make drainage    -0.5910largest investment higher', '0.3422companies increasing taxes    -0.4584mclane kuster used 293', '0.3309rhode island 28    -0.4484bodies desert buried', '0.3283americans millions jobs    -0.4442      know 2013', '0.3225      cities 39    -0.4394       pinellas', '0.3118intensive care unit cause    -0.4302obamas approval rating', '0.3009   efforts rein    -0.4257says republican gubernatorial candidate', '0.2930extremists hijacked broad based    -0.4224pentagon obama administration', '0.2799advocacy immigration increases    -0.3769books automatically little', '0.2757       00 spent    -0.3733physical fitness', '0.2747conducted nationwide    -0.3713approved abbott', '0.2690citizens black males    -0.3589   far national', '0.2447jeb bush held million    -0.3585campaign idea going', '0.2320900 florida jobs    -0.3473family taxes today', '0.2151businesses created million    -0.3472 india expected', '0.2143published polls    -0.3406   plan student', '0.2039office gasoline    -0.3383approved bills previous', '0.2015shirts bangladesh trump    -0.3376previous 12 years combined', '0.2006city portland manager    -0.3290sector whack governments growing', '0.1985felt americans hating    -0.3268previous democrat regimes', '0.1954colorado congressional candidate    -0.3123fundputs mandate local', '0.1933dollars political campaigns    -0.3108launched twice strikes countries', '0.1930set foot oregon courtroom    -0.3074engage american troops fourth', '0.1886considered extreme    -0.3008   engage risky', '0.1879sequestration spending cuts eliminated    -0.2890england patriots', '0.1876represent 75 percent    -0.2792million november', '0.1855idea turn social    -0.2765employee company makes', '0.1852dane county kathleen falks    -0.2751people florida going able', '0.1832john mccain seven points    -0.2695  anderson road', '0.1831congress cut social security    -0.2646         regard', '0.1827rosemary lehmberg purchased    -0.2486       excluded', '0.1799court justices deciding    -0.2449people florida going', '0.1775houston national    -0.243133 votes repeal', '0.1735buffalos solarcity project andrew    -0.2415raise income levels', '0.1732military installations world    -0.2393congress redistricting process', '0.1722billion government shutdown    -0.2341percent overhead medicare', '0.1717leader senate said    -0.2294    received 60', '0.1714money provide ipod touch    -0.2239fight pollution combat', '0.1706     mark udall    -0.2211goes far obamacare medicare', '0.1685      profit 22    -0.2128          seals', '0.1668 rules campaign    -0.2087people world wealth', '0.1660sen rob portman calls    -0.2087decade america budget', '0.1653paid departments    -0.2080redistricting plans cut democrat', '0.1648percent retirees collect    -0.2052says hurd cosponsored militarize', '0.1633   millionaires    -0.2052family saw income', '0.1631legislation open billions taxpayer    -0.2036  foreign money', '0.1626paying taxes nearly 14    -0.2034negotiating teachers work free', '0.1623income united states nationally    -0.2026energy considering rate increase', '0.1617household incomes went state    -0.2026congress reduced salaries great', '0.1590convicted felons vote    -0.2025  says 48 years']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = '/content/drive/MyDrive/Fake News Detection/final_model.sav'\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#function to run for prediction\n",
        "def detecting_fake_news(var):    \n",
        "#retrieving the best model for prediction call\n",
        "    load_model = pickle.load(open(final_model, 'rb'))\n",
        "    prediction = load_model.predict([var])\n",
        "    prob = load_model.predict_proba([var])\n",
        "\n",
        "    return (print(\"The given statement is \",prediction[0]),\n",
        "        print(\"The truth probability score is \",prob[0][1]))\n",
        "\n",
        "# detecting_fake_news('Says John McCain has done nothing to help the vets.')"
      ],
      "metadata": {
        "id": "SLIuxvCf8DwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eab2f6e-f3f3-482a-a392-6bb15e5afd46"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given statement is  True\n",
            "The truth probability score is  0.5890252528883622\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#doc_new = ['obama is running for president in 2016']\n",
        "\n",
        "var = input(\"Please enter the news text you want to verify: \")\n",
        "print(\"You entered: \" + str(var))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    detecting_fake_news(var)"
      ],
      "metadata": {
        "id": "Yv-Ngrqt7RTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd483f70-e63d-4530-bb60-a106dd23b502"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the news text you want to verify: Says John McCain has done nothing to help the vets.\n",
            "You entered: Says John McCain has done nothing to help the vets.\n",
            "The given statement is  True\n",
            "The truth probability score is  0.5890252528883622\n"
          ]
        }
      ]
    }
  ]
}